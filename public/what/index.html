<!DOCTYPE html>
<html><head lang="en"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>What - dhmnr.sh</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Analyzing Register Pressure with ptxas
You&rsquo;ve written your kernel. How do you know if it&rsquo;s efficient? The ptxas assembler (which converts PTX to SASS) tells you exactly what resources your kernel consumes — and this directly determines occupancy.
The Basic Command
nvcc -ptx -arch=sm_80 kernel.cu -o kernel.ptx
ptxas -arch=sm_80 -v kernel.ptx
Or in one shot:
nvcc -arch=sm_80 --ptxas-options=-v kernel.cu
Reading the Output
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &#39;matmul_kernel&#39; for &#39;sm_80&#39;
ptxas info    : Function properties for matmul_kernel
    72 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 64 registers, 8192 bytes smem, 400 bytes cmem[0]
Let&rsquo;s break this down:" />
	<meta property="og:image" content=""/>
	<meta property="og:url" content="http://localhost:1313/what/">
  <meta property="og:site_name" content="dhmnr.sh">
  <meta property="og:title" content="What">
  <meta property="og:description" content="Analyzing Register Pressure with ptxas You’ve written your kernel. How do you know if it’s efficient? The ptxas assembler (which converts PTX to SASS) tells you exactly what resources your kernel consumes — and this directly determines occupancy.
The Basic Command nvcc -ptx -arch=sm_80 kernel.cu -o kernel.ptx ptxas -arch=sm_80 -v kernel.ptx Or in one shot:
nvcc -arch=sm_80 --ptxas-options=-v kernel.cu Reading the Output ptxas info : 0 bytes gmem ptxas info : Compiling entry function &#39;matmul_kernel&#39; for &#39;sm_80&#39; ptxas info : Function properties for matmul_kernel 72 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads ptxas info : Used 64 registers, 8192 bytes smem, 400 bytes cmem[0] Let’s break this down:">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2026-01-31T01:08:38-08:00">
    <meta property="article:modified_time" content="2026-01-31T01:08:38-08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="What">
  <meta name="twitter:description" content="Analyzing Register Pressure with ptxas You’ve written your kernel. How do you know if it’s efficient? The ptxas assembler (which converts PTX to SASS) tells you exactly what resources your kernel consumes — and this directly determines occupancy.
The Basic Command nvcc -ptx -arch=sm_80 kernel.cu -o kernel.ptx ptxas -arch=sm_80 -v kernel.ptx Or in one shot:
nvcc -arch=sm_80 --ptxas-options=-v kernel.cu Reading the Output ptxas info : 0 bytes gmem ptxas info : Compiling entry function &#39;matmul_kernel&#39; for &#39;sm_80&#39; ptxas info : Function properties for matmul_kernel 72 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads ptxas info : Used 64 registers, 8192 bytes smem, 400 bytes cmem[0] Let’s break this down:">

        <link href="http://localhost:1313/css/fonts.11a1877508139eac0b5b4852ceb110c35641b3533321e66e39149e901ed5756b.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="http://localhost:1313/css/main.2d8b5d025466bd6ddaba53abadd82452f7b979866a58623830289b480f93bb3b.css" />
		<link id="darkModeStyle" rel="stylesheet" type="text/css" href="http://localhost:1313/css/dark.3cc53e265be0aadc134ff08f276085599313959408ee8c32d9cf35ce71670fff.css"  disabled /><link rel="stylesheet" href="http://localhost:1313/katex/katex.min.css ">
		<script defer src="http://localhost:1313/katex/katex.min.js"></script>
		<script defer src="http://localhost:1313/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
		
		<script>
			document.addEventListener("DOMContentLoaded", function() {
					renderMathInElement(document.body, {
							delimiters: [
									{left: "$$", right: "$$", display: true},
									{left: "$", right: "$", display: false}
							]
					});
			});
		</script>
		
		
		<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/jetbrains-mono.027bd4d70293c64700e7ad92bd136797198199ca99c9ea54541f4b41805e9006.css">
		
		
		<link rel="stylesheet" type="text/css" href="http://localhost:1313/css/speedrun.ff7cd40ab2a8b7b70c253c14e084f61b5d4ce5c3190ea3b5c440e26f0fa3a52d.css">
		
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="http://localhost:1313/">dhmnr.sh</a>
	</div>
	<nav>
		
		<a href="/">home</a>
		
		<a href="/posts">posts</a>
		
		<a href="/about">about</a>
		
		<a href="/tags">tags</a>
		
		<button id="dark-mode-toggle" class="nav-toggle" onclick="toggleTheme()" aria-label="Toggle dark mode" type="button"><svg class="feather" viewBox="0 0 24 24" fill="none" stroke="#232333" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg></button>
		<script src="http://localhost:1313/js/themetoggle.js"></script>
		
	</nav>
</header>

<main>
  <article>
    <div class="post-container">
      
      <div class="post-content">
        <div class="title">
          <h1 class="title">What</h1>
          <div class="meta">Posted on Jan 31, 2026 <span class="draft-label">DRAFT</span> </div>
        </div>
        
        <section class="body">
          <h2 id="analyzing-register-pressure-with-ptxas">Analyzing Register Pressure with ptxas</h2>
<p>You&rsquo;ve written your kernel. How do you know if it&rsquo;s efficient? The <code>ptxas</code> assembler (which converts PTX to SASS) tells you exactly what resources your kernel consumes — and this directly determines occupancy.</p>
<h3 id="the-basic-command">The Basic Command</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvcc -ptx -arch<span style="color:#f92672">=</span>sm_80 kernel.cu -o kernel.ptx
</span></span><span style="display:flex;"><span>ptxas -arch<span style="color:#f92672">=</span>sm_80 -v kernel.ptx
</span></span></code></pre></div><p>Or in one shot:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvcc -arch<span style="color:#f92672">=</span>sm_80 --ptxas-options<span style="color:#f92672">=</span>-v kernel.cu
</span></span></code></pre></div><h3 id="reading-the-output">Reading the Output</h3>
<pre tabindex="0"><code>ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &#39;matmul_kernel&#39; for &#39;sm_80&#39;
ptxas info    : Function properties for matmul_kernel
    72 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 64 registers, 8192 bytes smem, 400 bytes cmem[0]
</code></pre><p>Let&rsquo;s break this down:</p>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th>What It Means</th>
          <th>Why It Matters</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Registers</strong></td>
          <td>Registers per thread</td>
          <td>Limits threads per SM. sm_80 has 65536 registers/SM. At 64 regs/thread, max 1024 threads = 32 warps.</td>
      </tr>
      <tr>
          <td><strong>smem</strong></td>
          <td>Shared memory per block</td>
          <td>Limits blocks per SM. sm_80 has 164KB configurable. 8KB/block allows many concurrent blocks.</td>
      </tr>
      <tr>
          <td><strong>cmem[0]</strong></td>
          <td>Constant memory for params</td>
          <td>Usually not a bottleneck. Kernel arguments live here.</td>
      </tr>
      <tr>
          <td><strong>stack frame</strong></td>
          <td>Per-thread local memory</td>
          <td>Bad sign — means arrays or spills. Lives in slow global memory.</td>
      </tr>
      <tr>
          <td><strong>spill stores/loads</strong></td>
          <td>Register spills</td>
          <td>Very bad. Means ptxas couldn&rsquo;t fit everything in registers.</td>
      </tr>
  </tbody>
</table>
<h3 id="the-occupancy-calculation">The Occupancy Calculation</h3>
<p>Here&rsquo;s how registers limit occupancy on sm_80 (A100):</p>
<pre tabindex="0"><code>Total registers per SM:     65,536
Max threads per SM:         2,048
Max warps per SM:           64
Max blocks per SM:          32

Your kernel uses 64 registers/thread:
  65,536 / 64 = 1,024 max threads
  1,024 / 32 = 32 warps
  Occupancy = 32/64 = 50%

If you reduced to 32 registers/thread:
  65,536 / 32 = 2,048 max threads
  2,048 / 32 = 64 warps
  Occupancy = 64/64 = 100%
</code></pre><h3 id="controlling-register-usage">Controlling Register Usage</h3>
<p><strong>Option 1: Compiler flag</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvcc -maxrregcount<span style="color:#f92672">=</span><span style="color:#ae81ff">32</span> kernel.cu
</span></span></code></pre></div><p>Forces the compiler to use at most 32 registers. If it can&rsquo;t fit, it spills to local memory (slow!).</p>
<p><strong>Option 2: Launch bounds</strong></p>
<pre tabindex="0"><code class="language-cuda" data-lang="cuda">__global__ __launch_bounds__(256, 4)  // 256 threads/block, want 4 blocks/SM
void kernel() { ... }
</code></pre><p>This hints to the compiler: &ldquo;I want 4 blocks of 256 threads on each SM.&rdquo; The compiler calculates: 4 × 256 = 1024 threads, with 65536 registers available, that&rsquo;s 64 registers/thread max.</p>
<p><strong>Option 3: PTX register declarations</strong></p>
<p>In raw PTX, you explicitly declare how many registers you need:</p>
<pre tabindex="0"><code class="language-ptx" data-lang="ptx">.reg .f32 %f&lt;32&gt;;    // Declare 32 float registers
.reg .u32 %r&lt;16&gt;;    // Declare 16 int registers
</code></pre><p><code>ptxas</code> will try to pack your code into these registers. If it can&rsquo;t, it spills.</p>
<h3 id="hunting-down-register-hogs">Hunting Down Register Hogs</h3>
<p>Sometimes you need to see <em>why</em> register usage is high. Dump the SASS:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvcc -arch<span style="color:#f92672">=</span>sm_80 -cubin kernel.cu
</span></span><span style="display:flex;"><span>cuobjdump -sass kernel.cubin
</span></span></code></pre></div><p>Or use Nsight Compute:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ncu --set full -o profile ./your_app
</span></span></code></pre></div><p>The &ldquo;Source&rdquo; view shows register usage per line of code. Look for:</p>
<ul>
<li>Large arrays that should be in shared memory</li>
<li>Loop-carried values the compiler couldn&rsquo;t optimize</li>
<li>Expensive operations (div, sqrt) that need many temporaries</li>
</ul>
<h3 id="a-real-example-reducing-register-pressure">A Real Example: Reducing Register Pressure</h3>
<p>Suppose you have a kernel using 96 registers (bad for occupancy):</p>
<pre tabindex="0"><code class="language-cuda" data-lang="cuda">__global__ void wasteful_kernel(float *data, int n) {
    float local_buffer[16];  // Oops: 16 floats = 16 registers minimum
    
    // ... compute ...
    
    for (int i = 0; i &lt; 16; i++) {
        local_buffer[i] = expensive_function(data[threadIdx.x + i * n]);
    }
    
    // ... use local_buffer ...
}
</code></pre><p>The fix: move to shared memory.</p>
<pre tabindex="0"><code class="language-cuda" data-lang="cuda">__global__ void efficient_kernel(float *data, int n) {
    __shared__ float shared_buffer[256 * 16];  // 16 floats per thread, 256 threads
    float *my_buffer = &amp;shared_buffer[threadIdx.x * 16];
    
    for (int i = 0; i &lt; 16; i++) {
        my_buffer[i] = expensive_function(data[threadIdx.x + i * n]);
    }
    
    // ... use my_buffer ...
}
</code></pre><p>Now those 16 floats live in shared memory instead of registers. Trade-off: slightly higher latency for access, but way better occupancy.</p>
<h3 id="the-spill-trap">The Spill Trap</h3>
<p>If you see this in <code>ptxas -v</code> output:</p>
<pre tabindex="0"><code>ptxas info    : Used 255 registers, 48 bytes spill stores, 48 bytes spill loads
</code></pre><p>You&rsquo;re in trouble. The compiler hit the 255-register limit and is spilling to local memory. Local memory is cached in L1/L2, but it&rsquo;s still much slower than registers.</p>
<p>Common causes:</p>
<ul>
<li>Too many live variables across a loop</li>
<li>Large structs passed by value</li>
<li>Unrolled loops with high intermediate values</li>
</ul>
<p>Fixes:</p>
<ul>
<li>Break computation into phases (recompute instead of store)</li>
<li>Use <code>#pragma unroll 1</code> to prevent over-unrolling</li>
<li>Move data to shared memory with explicit loads/stores</li>
</ul>
<h3 id="quick-reference-sm_80-a100-limits">Quick Reference: sm_80 (A100) Limits</h3>
<table>
  <thead>
      <tr>
          <th>Resource</th>
          <th>Per SM</th>
          <th>Per Block Max</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Registers</td>
          <td>65,536</td>
          <td>65,536</td>
      </tr>
      <tr>
          <td>Shared Memory</td>
          <td>164 KB (configurable)</td>
          <td>164 KB</td>
      </tr>
      <tr>
          <td>Threads</td>
          <td>2,048</td>
          <td>1,024</td>
      </tr>
      <tr>
          <td>Warps</td>
          <td>64</td>
          <td>32</td>
      </tr>
      <tr>
          <td>Blocks</td>
          <td>32</td>
          <td>—</td>
      </tr>
  </tbody>
</table>
<p>Use <code>deviceQuery</code> from the CUDA samples to get these numbers for your specific GPU.</p>
<hr>

        </section>
        <div class="post-tags">
          
        </div>
      </div>

      
      
    </div>

    </article>
</main>
<footer>
  <div style="display:flex"></div>
  <div class="footer-info">
    2026  <a
      href="https://github.com/athul/archie">Archie Theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
  </div>
</footer>

</div>
    </body>
</html>
